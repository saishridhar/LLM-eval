{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "together = OpenAI(api_key=\"API_KEY\", base_url=\"https://api.together.xyz/v1\")\n",
    "client = Anthropic( api_key = \"API_KEY\")\n",
    "gpt = OpenAI(api_key=\"API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory path\n",
    "directory = \"../final\"\n",
    "\n",
    "# Get the list of file names in the directory\n",
    "file_list = os.listdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "able = ['_ll70B.json','_mix.json','_gpt4.json','_mis.json','_gpt3.json','_ll7B.json','_ll13B.json']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Llama-2-70b-chat-hf_results.json',\n",
       " 'Mixtral-8x7B-Instruct-v0.1_results.json',\n",
       " 'gpt-4-0125-preview_results.json',\n",
       " 'Mistral-7B-Instruct-v0.2_results.json',\n",
       " 'gpt-3.5-turbo-0125_results.json',\n",
       " 'Llama-2-7b-chat-hf_results.json',\n",
       " 'Llama-2-13b-chat-hf_results.json']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Claude Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval(context,question,prediction,answer) -> float:\n",
    "    QUESTION = f\"\"\"{context}\\n Given the above context, Answer the question that follows:\\n {question}\"\"\"\n",
    "    MODEL_OUTPUT = prediction\n",
    "    GROUND_TRUTH = answer\n",
    "\n",
    "    instruction = f'''<Instructions> You will be evaluating whether a language model's output to a question means essentially the same thing as the provided ground truth answer, even if not worded identically.\n",
    "\n",
    "The question is: <question> {QUESTION} </question>\n",
    "\n",
    "The language model's output is: <model_output> {MODEL_OUTPUT} </model_output>\n",
    "\n",
    "The ground truth answer is: <ground_truth> {GROUND_TRUTH} </ground_truth>\n",
    "\n",
    "To determine if the model output means the same thing as the ground truth:\n",
    "\n",
    "Carefully read and understand the meaning of the model output and ground truth. Ignore minor wording or formatting differences.\n",
    "\n",
    "Consider whether the key facts, ideas, and opinions expressed in the model output align with those in the ground truth.\n",
    "\n",
    "The model output doesn't need to cover every single detail in the ground truth. As long as it captures the main points without saying anything contradictory, that is sufficient.\n",
    "\n",
    "First, explain your reasoning: <reasoning> </reasoning>\n",
    "\n",
    "Then, output your final result, which should be either: <result>YES</result> if the model output captures the key meaning of the ground truth, or <result>NO</result> if the model output fails to capture the essential meaning, or contradicts the ground truth in some way. </Instructions>'''\n",
    "    \n",
    "    message = client.messages.create(\n",
    "    model=\"claude-3-haiku-20240307\",\n",
    "    max_tokens=1024,\n",
    "    temperature=0.2,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": instruction}\n",
    "    ]\n",
    "    )\n",
    "\n",
    "    text = message.content[0].text\n",
    "\n",
    "    pattern_reason = r'<reasoning>\\s*(.*?)\\s*</reasoning>'\n",
    "    pattern_result = r'<result>\\s*(.*?)\\s*</result>'\n",
    "    match_reason = re.search(pattern_reason, text, re.DOTALL)\n",
    "    match_result = re.search(pattern_result, text, re.DOTALL)\n",
    "    if match_reason:\n",
    "        reason = match_reason.group(1)\n",
    "    else:\n",
    "        reason = \" \"\n",
    "\n",
    "    if match_result:\n",
    "        extracted_text = match_result.group(1)\n",
    "        if extracted_text == \"YES\":\n",
    "            result = 1.0\n",
    "        if extracted_text == \"NO\":\n",
    "            result = 0.0\n",
    "    else:\n",
    "        result = -1.0\n",
    "    \n",
    "    return result,reason"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Open Source LLM eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function that defines the usage of Open Source LLMs from the together api. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'NousResearch/Nous-Hermes-2-Yi-34B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_op(context,question,prediction,answer) -> float:\n",
    "    QUESTION = f\"\"\"{context}\\n Given the above context, Answer the question that follows:\\n {question}\"\"\"\n",
    "    #QUESTION = f\"\"\"{question}\"\"\"\n",
    "    MODEL_OUTPUT = prediction\n",
    "    GROUND_TRUTH = answer\n",
    "\n",
    "    instruction = f'''<Instructions> You will be evaluating whether a language model's output to a question means essentially the same thing as the provided ground truth answer, even if not worded identically.\n",
    "\n",
    "The question is: <question> {QUESTION} </question>\n",
    "\n",
    "The language model's output is: <model_output> {MODEL_OUTPUT} </model_output>\n",
    "\n",
    "The ground truth answer is: <ground_truth> {GROUND_TRUTH} </ground_truth>\n",
    "\n",
    "To determine if the model output means the same thing as the ground truth:\n",
    "\n",
    "Carefully read and understand the meaning of the model output and ground truth. Ignore minor wording or formatting differences.\n",
    "\n",
    "Consider whether the key facts, ideas, and opinions expressed in the model output align with those in the ground truth.\n",
    "\n",
    "The model output doesn't need to cover every single detail in the ground truth. As long as it captures the main points without saying anything contradictory, that is sufficient.\n",
    "\n",
    "First, explain your reasoning within the tags <reasoning> </reasoning>\n",
    "\n",
    "Then, output your final result, which should be either: <result>YES</result> if the model output captures the key meaning of the ground truth, or <result>NO</result> if the model output fails to capture the essential meaning, or contradicts the ground truth in some way. </Instructions>'''\n",
    "    response = together.chat.completions.create(\n",
    "  model=MODEL,\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": instruction}],\n",
    "  temperature=0.0\n",
    "    )\n",
    "\n",
    "    text = response.choices[0].message.content\n",
    "    print(text)\n",
    "    pattern_reason = r'<reasoning>\\s*(.*?)\\s*</reasoning>'\n",
    "    pattern_result = r'<result>\\s*(.*?)\\s*</result>'\n",
    "    match_reason = re.search(pattern_reason, text, re.DOTALL)\n",
    "    match_result = re.search(pattern_result, text, re.DOTALL)\n",
    "    if match_reason:\n",
    "        reason = match_reason.group(1)\n",
    "    else:\n",
    "        reason = \" \"\n",
    "\n",
    "    if match_result:\n",
    "        extracted_text = match_result.group(1)\n",
    "        if extracted_text == \"YES\":\n",
    "            result = 1.0\n",
    "        if extracted_text == \"NO\":\n",
    "            result = 0.0\n",
    "    else:\n",
    "        result = -1.0\n",
    "    \n",
    "    return result,reason\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPT_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function that uses GPT-4 to perform evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_op(context,question,prediction,answer) -> float:\n",
    "    QUESTION = f\"\"\"{context}\\n Given the above context, Answer the question that follows:\\n {question}\"\"\"\n",
    "    #QUESTION = f\"\"\"{question}\"\"\"\n",
    "    MODEL_OUTPUT = prediction\n",
    "    GROUND_TRUTH = answer\n",
    "\n",
    "    instruction = f'''<Instructions> You will be evaluating whether a language model's output to a question means essentially the same thing as the provided ground truth answer, even if not worded identically.\n",
    "\n",
    "The question is: <question> {QUESTION} </question>\n",
    "\n",
    "The language model's output is: <model_output> {MODEL_OUTPUT} </model_output>\n",
    "\n",
    "The ground truth answer is: <ground_truth> {GROUND_TRUTH} </ground_truth>\n",
    "\n",
    "To determine if the model output means the same thing as the ground truth:\n",
    "\n",
    "Carefully read and understand the meaning of the model output and ground truth. Ignore minor wording or formatting differences.\n",
    "\n",
    "Consider whether the key facts, ideas, and opinions expressed in the model output align with those in the ground truth.\n",
    "\n",
    "The model output doesn't need to cover every single detail in the ground truth. As long as it captures the main points without saying anything contradictory, that is sufficient.\n",
    "\n",
    "First, explain your reasoning within the tags <reasoning> </reasoning>\n",
    "\n",
    "Then, output your final result, which should be either: <result>YES</result> if the model output captures the key meaning of the ground truth, or <result>NO</result> if the model output fails to capture the essential meaning, or contradicts the ground truth in some way. </Instructions>'''\n",
    "    response = gpt.chat.completions.create(\n",
    "  model='gpt-4-0125-preview',\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": instruction}],\n",
    "  temperature=0.0\n",
    "    )\n",
    "\n",
    "    text = response.choices[0].message.content\n",
    "    print(text)\n",
    "    pattern_reason = r'<reasoning>\\s*(.*?)\\s*</reasoning>'\n",
    "    pattern_result = r'<result>\\s*(.*?)\\s*</result>'\n",
    "    match_reason = re.search(pattern_reason, text, re.DOTALL)\n",
    "    match_result = re.search(pattern_result, text, re.DOTALL)\n",
    "    if match_reason:\n",
    "        reason = match_reason.group(1)\n",
    "    else:\n",
    "        reason = \" \"\n",
    "\n",
    "    if match_result:\n",
    "        extracted_text = match_result.group(1)\n",
    "        if extracted_text == \"YES\":\n",
    "            result = 1.0\n",
    "        if extracted_text == \"NO\":\n",
    "            result = 0.0\n",
    "    else:\n",
    "        result = -1.0\n",
    "    \n",
    "    return result,reason\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reason Ablation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_able(context,question,prediction,answer) -> float:\n",
    "    QUESTION = f\"\"\"{context}\\n Given the above context, Answer the question that follows:\\n {question}\"\"\"\n",
    "    #QUESTION = f\"\"\"{question}\"\"\"\n",
    "    MODEL_OUTPUT = prediction\n",
    "    GROUND_TRUTH = answer\n",
    "\n",
    "    instruction = f'''<Instructions> You will be evaluating whether a language model's output to a question means essentially the same thing as the provided ground truth answer, even if not worded identically.\n",
    "\n",
    "The question is <question> {QUESTION} </question>    \n",
    "The language model's output is: <model_output> {MODEL_OUTPUT} </model_output>\n",
    "\n",
    "The ground truth answer is: <ground_truth> {GROUND_TRUTH} </ground_truth>\n",
    "\n",
    "To determine if the model output means the same thing as the ground truth:\n",
    "\n",
    "Carefully read and understand the meaning of the model output and ground truth. Ignore minor wording or formatting differences.\n",
    "\n",
    "Consider whether the key facts, ideas, and opinions expressed in the model output align with those in the ground truth.\n",
    "\n",
    "The model output doesn't need to cover every single detail in the ground truth. As long as it captures the main points without saying anything contradictory, that is sufficient.\n",
    "\n",
    "Output your final result, which should be either: <result>YES</result> if the model output captures the key meaning of the ground truth or <result>NO</result> if the model output fails to capture the essential meaning, or contradicts the ground truth in some way. </Instructions>'''\n",
    "    response = together.chat.completions.create(\n",
    "  model='NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO',\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": instruction}],\n",
    "  temperature=0.0\n",
    "    )\n",
    "\n",
    "    text = response.choices[0].message.content\n",
    "    print(text)\n",
    "    pattern_yes = r'(?i)YES'\n",
    "    pattern_no = r'(?i)NO'\n",
    "    match_yes = re.search(pattern_yes, text, re.DOTALL)\n",
    "    match_no = re.search(pattern_no, text, re.DOTALL)\n",
    "    \n",
    "    if match_yes:\n",
    "            result = 1.0\n",
    "    \n",
    "    elif match_no:\n",
    "            result = 0.0\n",
    "       \n",
    "    else:\n",
    "        result = -1.0\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traditional Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertscore = load(\"bertscore\")\n",
    "bleurt = load(\"bleurt\",module_type=\"metric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_match(predictions,answer):\n",
    "    em = load(\"exact_match\")\n",
    "    result = em.compute(predictions=[predictions], references=[answer])\n",
    "    score = result[\"exact_match\"]\n",
    "    #print(score)\n",
    "    return score\n",
    "\n",
    "    \n",
    "def BLEU(predictions,answer):\n",
    "    bleu = load(\"bleu\")\n",
    "    result = bleu.compute(predictions=[predictions], references=[answer])\n",
    "    score = result[\"bleu\"]\n",
    "    #print(score)\n",
    "    return score\n",
    "   \n",
    "\n",
    "def BLEURT(predictions,answer):\n",
    "    result = bleurt.compute(predictions=[predictions], references=[answer])\n",
    "    score = result['scores'][0]\n",
    "    return score\n",
    "\n",
    "\n",
    "def BERTscore(predictions,answer):\n",
    "    result = bertscore.compute(predictions=[predictions], references=[answer], lang= 'en')\n",
    "    p = np.array(result['precision'])\n",
    "    r = np.array(result['recall'])\n",
    "    score = 2*((p*r)/(p+r))\n",
    "    return score[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run on predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('../results/original.json',orient='records',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['human_eval'] = df['human_eval'].replace({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>NO</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "[+] reason_ll70B.json Done...\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>NO</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "[+] reason_mix.json Done...\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "[+] reason_gpt4.json Done...\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>NO</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>NO</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "[+] reason_mis.json Done...\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>NO</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "[+] reason_gpt3.json Done...\n",
      "<result>NO</result>\n",
      "<result>NO</result>\n",
      "<result>NO</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>NO</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>NO</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "[+] reason_ll7B.json Done...\n",
      "<result>NO</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>NO</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>YES</result>\n",
      "<result>NO</result>\n",
      "<result>YES</result>\n",
      "[+] reason_ll13B.json Done...\n"
     ]
    }
   ],
   "source": [
    "# Default\n",
    "for i in range(0,len(file_list)):\n",
    "    predictions = pd.read_json( \"../final/\"+file_list[i],orient='records',lines=True)\n",
    "    try:\n",
    "        df['prediction'] = predictions['prediction']\n",
    "    except:\n",
    "        df['prediction'] = predictions[file_list[i][:-13]+'_pred']\n",
    "        predictions = predictions.rename(columns={file_list[i][:-13]+'_pred': 'prediction'})\n",
    "    \n",
    "    results = df.apply(lambda row: get_eval_able(row['llm_context'], row['question'],row[f'prediction'],row['answer']), axis=1)\n",
    "    predictions[f'mix_eval'] = results\n",
    "    \n",
    "    # Traditional Metrics\n",
    "    predictions['exact_match'] = predictions.apply(lambda row: exact_match(row['predictions'],row['answer']), axis=1)\n",
    "    print('EM Done')\n",
    "    predictions['BLEU'] = predictions.apply(lambda row: BLEU(row['predictions'],row['answer']), axis=1)\n",
    "    print('BLEU Done')\n",
    "    predictions['BERTScore'] = predictions.apply(lambda row: BERTscore(row['predictions'],row['answer']), axis=1)\n",
    "    print('BERTscore Done')\n",
    "    predictions['BLEURT'] = predictions.apply(lambda row: BLEURT(row['predictions'],row['answer']), axis=1)\n",
    "    predictions['BLEURT_norm'] = (predictions['BLEURT'] - predictions['BLEURT'].min()) / (predictions['BLEURT'].max() - predictions['BLEURT'].min())\n",
    "    print('BLEURT Done')\n",
    "    print(f'[+] {i} Done...')\n",
    "\n",
    "\n",
    "# Reason Ablations\n",
    "for i in range(0,len(file_list)):\n",
    "    predictions = pd.read_json( \"../final/\"+file_list[i],orient='records',lines=True)\n",
    "    try:\n",
    "        df['prediction'] = predictions['prediction']\n",
    "    except:\n",
    "        df['prediction'] = predictions[file_list[i][:-13]+'_pred']\n",
    "        predictions = predictions.rename(columns={file_list[i][:-13]+'_pred': 'prediction'})\n",
    "    \n",
    "    results = df.apply(lambda row: get_eval_able(row['llm_context'], row['question'],row[f'prediction'],row['answer']), axis=1)\n",
    "    predictions[f'mix_eval'] = results\n",
    "    print(f'[+] reason{able[i]} Done...')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS594",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
